{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1trzgCkH6QX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "model.trainable = False\n",
        "\n",
        "model = Sequential([model, GlobalMaxPooling2D()])\n",
        "#model.summary()\n",
        "\n",
        "def extract_features(img_path,model):\n",
        "    img = image.load_img(img_path,target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expand_img = np.expand_dims(img_array,axis=0)\n",
        "    preprocessed_img = preprocess_input(expand_img)\n",
        "    result_to_resnet = model.predict(preprocessed_img)\n",
        "    flatten_result = result_to_resnet.flatten()\n",
        "    # normalizing\n",
        "    result_normlized = flatten_result / norm(flatten_result)\n",
        "\n",
        "    return result_normlized\n",
        "#print(os.listdir('fashion_small/images'))\n",
        "img_files = []\n",
        "\n",
        "for fashion_images in os.listdir('fashion_small/images'):\n",
        "    images_path = os.path.join('fashion_small/images', fashion_images)\n",
        "    img_files.append(images_path)\n",
        "\n",
        "# extracting image features\n",
        "image_features = []\n",
        "\n",
        "for files in tqdm(img_files):\n",
        "    features_list = extract_features(files, model)\n",
        "    image_features.append(features_list)\n",
        "\n",
        "pickle.dump(image_features, open(\"image_features_embedding.pkl\", \"wb\"))\n",
        "pickle.dump(img_files, open(\"img_files.pkl\", \"wb\"))"
      ]
    }
  ]
}